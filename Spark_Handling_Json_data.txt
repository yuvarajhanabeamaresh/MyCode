Single line json

Multi Line json
use the below command,if your json is multiline,else you will get the corrupt data
----------------val df1= spark.read.option("multiline",true).json("F:\\yuv\\JsonSample.json")-------------


--------------------Link to handle json nested data----------------------------
https://docs.databricks.com/spark/latest/dataframes-datasets/complex-nested-data.html

----------------refer to handle json data conatining array elements(not nested)-----------------
https://medium.com/@newfrontcreative/working-with-apache-spark-dataframes-json-and-the-good-ol-structtype-6291bdcd44bd


get_json_object()
from_json()
to_json()
explode()
selectExpr()
The above functions are partv  of org.apache.spark.sql.functions package. thses are used in select statements,atleast few.

to handle nested data and to fetch the nested data into the dataframe columns,we use the above methods provided by spark.sql.functions package.
----from_json() is a variant of get_json_object().from_json uses the schema(struct type is given in the above link) to fetch neted data whereas get_json_object() doesn't uses it.

To write a dataframe(having json data) to kafka,we can use to_json method  which converts dataframe to json string so that it can be sent to kafka.

